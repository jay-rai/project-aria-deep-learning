{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Aria Deep Learning Project - CSE144 Project\n",
    "\n",
    "This assumes you have installed everything from requirements.txt. It is highly recommended to make a new conda environment `conda create -n \"env_name\" python=3.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datasets and Dataset preprocessing\n",
    "The first thing we need to do is get the data from Project Aria, please read the readme if you need an example of how to get the data\n",
    "\n",
    "This assumes you have the same file structure as the github repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames(in_path, out_path):\n",
    "    \"\"\"\n",
    "    takes in an input file path, and output file path. Utilizing\n",
    "    cv2 we save each image as frame_framecount.jpg\n",
    "    \"\"\"\n",
    "    os.makedirs(out_path, exist_ok=True)\n",
    "    video = cv2.VideoCapture(in_path)\n",
    "\n",
    "    success, frame = video.read()\n",
    "    count = 0\n",
    "    try:\n",
    "        while success:\n",
    "            cv2.imwrite(f\"{out_path}/frame_{count}.jpg\", frame)\n",
    "            success, frame = video.read()\n",
    "            count += 1\n",
    "\n",
    "        video.release()\n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid file paths, getting frames\n"
     ]
    }
   ],
   "source": [
    "input_file_path = \"Raw Data/hot3d/video.mp4\"\n",
    "output_file_path = \"Output Data/test_output_frames/\"\n",
    "\n",
    "if os.path.exists(output_file_path) and os.path.exists(input_file_path):\n",
    "    print(\"Valid file paths, getting frames\")\n",
    "    # get_frames(input_file_path, output_file_path)\n",
    "else:\n",
    "    print(\"Invalid file path, wont get frames\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our goal is to fine tune the *LLaVa-Next* model on a custom data set there is a lot more data preperation needed, one of the main difference and improvments of *LLaVa-Next* over *LLaVa* isis that it uses AnyRes to increase image resolution. This also means when we prepare the data, the model wont take in an image, but rather `pixel values` "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llava",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
